{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPDL4UgmDEmg"
   },
   "source": [
    "Step 1:\n",
    "EDA STEPS:\n",
    "1.Indexing data\n",
    "\n",
    "2.Visualize data(check the statistical data for each column)\n",
    "\n",
    "3.Barchart/piechart(default rate in different regions, default rate in different types)\n",
    "\n",
    "4.Attribute(numeric(correlation),rank the top 10 correlation),\n",
    "EDA\n",
    "https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction\n",
    "simple histogram and distribution.\n",
    "\n",
    "5. Correlation (with the target varaible)\n",
    "\n",
    "Step 2:\n",
    "toy_data = df.head(100)\n",
    "\n",
    "pre-processing\n",
    "missing value (impute(), delete,)\n",
    "categorical varaible (onehot encoding)\n",
    "outlier\n",
    "\n",
    "Step 3:\n",
    "Model:\n",
    "\n",
    "1.Naive-Bayes\n",
    "\n",
    "2.Logistic regression\n",
    "\n",
    "3.Neuro Network\n",
    "\n",
    "4.Decision tree\n",
    "\n",
    "5. Random Forest\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "6. Adaboost\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "\n",
    "Step 3:\n",
    "Evaluate the model and compare it\n",
    "cross_val_score\n",
    "accuracy, sensitivity...\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "text",
    "id": "EcGLfDjpDEmm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>total_bal_il</th>\n",
       "      <th>il_util</th>\n",
       "      <th>open_rv_12m</th>\n",
       "      <th>open_rv_24m</th>\n",
       "      <th>max_bal_bc</th>\n",
       "      <th>all_util</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <th>inq_fi</th>\n",
       "      <th>total_cu_tl</th>\n",
       "      <th>inq_last_12m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501    1296599     5000.0       5000.0           4975.0   36 months   \n",
       "1  1077430    1314167     2500.0       2500.0           2500.0   60 months   \n",
       "2  1077175    1313524     2400.0       2400.0           2400.0   36 months   \n",
       "3  1076863    1277178    10000.0      10000.0          10000.0   36 months   \n",
       "4  1075358    1311748     3000.0       3000.0           3000.0   60 months   \n",
       "\n",
       "   int_rate  installment grade sub_grade     ...      total_bal_il il_util  \\\n",
       "0     10.65       162.87     B        B2     ...               NaN     NaN   \n",
       "1     15.27        59.83     C        C4     ...               NaN     NaN   \n",
       "2     15.96        84.33     C        C5     ...               NaN     NaN   \n",
       "3     13.49       339.31     C        C1     ...               NaN     NaN   \n",
       "4     12.69        67.79     B        B5     ...               NaN     NaN   \n",
       "\n",
       "  open_rv_12m  open_rv_24m max_bal_bc all_util total_rev_hi_lim inq_fi  \\\n",
       "0         NaN          NaN        NaN      NaN              NaN    NaN   \n",
       "1         NaN          NaN        NaN      NaN              NaN    NaN   \n",
       "2         NaN          NaN        NaN      NaN              NaN    NaN   \n",
       "3         NaN          NaN        NaN      NaN              NaN    NaN   \n",
       "4         NaN          NaN        NaN      NaN              NaN    NaN   \n",
       "\n",
       "  total_cu_tl inq_last_12m  \n",
       "0         NaN          NaN  \n",
       "1         NaN          NaN  \n",
       "2         NaN          NaN  \n",
       "3         NaN          NaN  \n",
       "4         NaN          NaN  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Thanks for Janio Alexander's code\n",
    "\n",
    "##importing packages and data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "loan=pd.read_csv('/Users/taotao/Desktop/loan/loan.csv',low_memory=False)\n",
    "loan_original=loan.copy()\n",
    "\n",
    "##import packages for visualizing data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "##visualize data\n",
    "loan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    49\n",
       "object     23\n",
       "int64       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of each type of column\n",
    "loan.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a random sample to run the analysis faster\n",
    "random_sample = loan.sample( n = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##drop some unrelated columns \n",
    "random_sample.drop(['id', 'member_id', 'emp_title', 'url', 'desc', 'zip_code', 'title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with missing value\n",
    "# drop columns with over 90% of null values, those variables won't help with the later analysis\n",
    "random_sample = random_sample.replace([0,' ','NULL'],np.nan)\n",
    "random_sample = random_sample.dropna(thresh=1000,how='all',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_amnt                         0\n",
       "funded_amnt                       0\n",
       "funded_amnt_inv                   1\n",
       "term                              0\n",
       "int_rate                          0\n",
       "installment                       0\n",
       "grade                             0\n",
       "sub_grade                         0\n",
       "emp_length                      561\n",
       "home_ownership                    0\n",
       "annual_inc                        0\n",
       "verification_status               0\n",
       "issue_d                           0\n",
       "loan_status                       0\n",
       "pymnt_plan                        0\n",
       "purpose                           0\n",
       "addr_state                        0\n",
       "dti                               5\n",
       "delinq_2yrs                    8166\n",
       "earliest_cr_line                  0\n",
       "inq_last_6mths                 5577\n",
       "mths_since_last_delinq         5152\n",
       "mths_since_last_record         8500\n",
       "open_acc                          0\n",
       "pub_rec                        8500\n",
       "revol_bal                        38\n",
       "revol_util                       41\n",
       "total_acc                         0\n",
       "initial_list_status               0\n",
       "out_prncp                      2938\n",
       "out_prncp_inv                  2938\n",
       "total_pymnt                     198\n",
       "total_pymnt_inv                 199\n",
       "total_rec_prncp                 201\n",
       "total_rec_int                   203\n",
       "last_pymnt_d                    194\n",
       "last_pymnt_amnt                 194\n",
       "next_pymnt_d                   2904\n",
       "last_credit_pull_d                0\n",
       "mths_since_last_major_derog    7450\n",
       "policy_code                       0\n",
       "application_type                  0\n",
       "tot_coll_amt                   8704\n",
       "tot_cur_bal                     812\n",
       "total_rev_hi_lim                813\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the columns with less than 90% null-value, I used different methods to fill them\n",
    "# for the dates with null value, in order to do the later analysis, fill the missing data with some impossible number to help identify them later\n",
    "r2 = random_sample.fillna({'last_pymnt_d':'Dec-1900','next_pymnt_d':'Dec-2100'})\n",
    "# in order to keep enough variables, I decide to keep filling other null value \n",
    "random_sample=random_sample.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loan_status indicator\n",
    "# 1: notcurent\n",
    "# 0: current\n",
    "random_sample[\"loan_status_ind\"] = np.where(random_sample[\"loan_status\"] != \"Current\",'0','1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6722\n",
       "0    3278\n",
       "Name: loan_status_ind, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample[\"loan_status_ind\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "term                     2\n",
       "grade                    7\n",
       "sub_grade               35\n",
       "emp_length              11\n",
       "home_ownership           4\n",
       "verification_status      3\n",
       "issue_d                 96\n",
       "loan_status             10\n",
       "pymnt_plan               1\n",
       "purpose                 14\n",
       "addr_state              48\n",
       "earliest_cr_line       514\n",
       "initial_list_status      2\n",
       "last_pymnt_d            79\n",
       "next_pymnt_d            29\n",
       "last_credit_pull_d      71\n",
       "application_type         2\n",
       "loan_status_ind          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique classes in each object column(check the categorical columns)\n",
    "random_sample.select_dtypes('object').apply(pd.Series.nunique, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. grade and sub_grade is not the predictable variable, so here I just delete the grade and sub_grade column.\n",
    "\n",
    "2. to simplify our model, I also delete the address state variable, becasue geographical factor doesn't really related to the loan condition.\n",
    "\n",
    "3. for some varaible with too many an objects such as dates, I use some actually days to represent the variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease the dimension of addr_state\n",
    "random_sample['addr_state'].unique()\n",
    "\n",
    "# Make a list with each of the regions by state.\n",
    "\n",
    "west = ['CA', 'OR', 'UT','WA', 'CO', 'NV', 'AK', 'MT', 'HI', 'WY', 'ID']\n",
    "south_west = ['AZ', 'TX', 'NM', 'OK']\n",
    "south_east = ['GA', 'NC', 'VA', 'FL', 'KY', 'SC', 'LA', 'AL', 'WV', 'DC', 'AR', 'DE', 'MS', 'TN' ]\n",
    "mid_west = ['IL', 'MO', 'MN', 'OH', 'WI', 'KS', 'MI', 'SD', 'IA', 'NE', 'IN', 'ND']\n",
    "north_east = ['CT', 'NY', 'PA', 'NJ', 'RI','MA', 'MD', 'VT', 'NH', 'ME']\n",
    "\n",
    "\n",
    "\n",
    "random_sample['region'] = np.nan\n",
    "\n",
    "def finding_regions(state):\n",
    "    if state in west:\n",
    "        return 'West'\n",
    "    elif state in south_west:\n",
    "        return 'SouthWest'\n",
    "    elif state in south_east:\n",
    "        return 'SouthEast'\n",
    "    elif state in mid_west:\n",
    "        return 'MidWest'\n",
    "    elif state in north_east:\n",
    "        return 'NorthEast'\n",
    "    \n",
    "\n",
    "\n",
    "random_sample['region'] = random_sample['addr_state'].apply(finding_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease the dimension of the object colunms\n",
    "earliest_cr_line=pd.to_datetime(random_sample['earliest_cr_line'])\n",
    "random_sample['today']='Jan-2016'\n",
    "today=pd.to_datetime(random_sample['today'])\n",
    "random_sample['credit_age']=today-earliest_cr_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transfer object to datetime\n",
    "## ????should I also transfer them into months? or date is just ok\n",
    "issue_d=pd.to_datetime(random_sample['issue_d'])\n",
    "last_credit_pull_d=pd.to_datetime(random_sample['last_credit_pull_d'])\n",
    "last_pymnt_d=pd.to_datetime(r2['last_pymnt_d'])\n",
    "next_pymnt_d=pd.to_datetime(r2['next_pymnt_d'])\n",
    "\n",
    "\n",
    "# clean the data\n",
    "# I already create the loan_status_ind to present the good loan and bad loan, so I also deleted the original column\n",
    "random_sample.drop(['grade','sub_grade','addr_state','loan_status'],axis=1,inplace=True)\n",
    "\n",
    "# use a different way to interpret date data\n",
    "random_sample['credit_card_length']=last_credit_pull_d-issue_d\n",
    "random_sample['pymnt_interval']=next_pymnt_d-last_pymnt_d\n",
    "\n",
    "\n",
    "# drop the original date data to decrease the number of features\n",
    "random_sample.drop(['issue_d','last_credit_pull_d','last_pymnt_d','next_pymnt_d','today','earliest_cr_line'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438881      31 days\n",
       "465734   31533 days\n",
       "595030      31 days\n",
       "282708      31 days\n",
       "347660      62 days\n",
       "437084      31 days\n",
       "656534      62 days\n",
       "468848   42034 days\n",
       "234703      31 days\n",
       "704282      31 days\n",
       "742352      31 days\n",
       "480300   42065 days\n",
       "765773      31 days\n",
       "856880   31199 days\n",
       "544931      31 days\n",
       "52371       31 days\n",
       "71122    31199 days\n",
       "670362      62 days\n",
       "76916       62 days\n",
       "444961   31137 days\n",
       "407742   31290 days\n",
       "549664      31 days\n",
       "665059       0 days\n",
       "493572      31 days\n",
       "280303      31 days\n",
       "742571      62 days\n",
       "111668      31 days\n",
       "771848      62 days\n",
       "154887   31625 days\n",
       "825291      31 days\n",
       "            ...    \n",
       "697892   31137 days\n",
       "621236      31 days\n",
       "92882    31290 days\n",
       "587740      31 days\n",
       "841445      31 days\n",
       "16083    32079 days\n",
       "772691      31 days\n",
       "406718       0 days\n",
       "787041      31 days\n",
       "178883   31046 days\n",
       "751742      31 days\n",
       "282376      31 days\n",
       "605833      31 days\n",
       "474305   42065 days\n",
       "280005   31199 days\n",
       "164916   31564 days\n",
       "687663      31 days\n",
       "875354   31137 days\n",
       "663153      31 days\n",
       "583662      31 days\n",
       "746751      31 days\n",
       "712812      31 days\n",
       "600224      31 days\n",
       "377006      31 days\n",
       "530892      31 days\n",
       "270317      62 days\n",
       "626555      62 days\n",
       "577265      31 days\n",
       "793296      31 days\n",
       "785743      62 days\n",
       "Name: pymnt_interval, Length: 10000, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample['pymnt_interval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the timedelta I created to float in order to do the further analysis\n",
    "random_sample['pymnt_interval']=random_sample['pymnt_interval'].astype('timedelta64[D]')\n",
    "random_sample['credit_age']=random_sample['credit_age'].astype('timedelta64[D]')\n",
    "random_sample['credit_card_length']=random_sample['credit_card_length'].astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because I fill the missing value of last payment day and next payment day with impossible numbers\n",
    "# I identified those impossible numbers as missing value again.\n",
    "pymnt_interval2=random_sample['pymnt_interval']\n",
    "pymnt_interval2.where(pymnt_interval2>100,31)\n",
    "random_sample['pymnt_interval']=pymnt_interval2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "term                    2\n",
       "emp_length             11\n",
       "home_ownership          4\n",
       "verification_status     3\n",
       "pymnt_plan              1\n",
       "purpose                14\n",
       "initial_list_status     2\n",
       "application_type        2\n",
       "loan_status_ind         2\n",
       "region                  5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample.select_dtypes('object').apply(pd.Series.nunique, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encoding Catergorical variables\n",
    "# one-hot encoding of categorical variables\n",
    "random_sample2 = pd.get_dummies(random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 438881 to 785743\n",
      "Data columns (total 77 columns):\n",
      "loan_amnt                              10000 non-null float64\n",
      "funded_amnt                            10000 non-null float64\n",
      "funded_amnt_inv                        10000 non-null float64\n",
      "int_rate                               10000 non-null float64\n",
      "installment                            10000 non-null float64\n",
      "annual_inc                             10000 non-null float64\n",
      "dti                                    10000 non-null float64\n",
      "delinq_2yrs                            9998 non-null float64\n",
      "inq_last_6mths                         10000 non-null float64\n",
      "mths_since_last_delinq                 9998 non-null float64\n",
      "mths_since_last_record                 10000 non-null float64\n",
      "open_acc                               10000 non-null float64\n",
      "pub_rec                                10000 non-null float64\n",
      "revol_bal                              10000 non-null float64\n",
      "revol_util                             10000 non-null float64\n",
      "total_acc                              10000 non-null float64\n",
      "out_prncp                              10000 non-null float64\n",
      "out_prncp_inv                          10000 non-null float64\n",
      "total_pymnt                            10000 non-null float64\n",
      "total_pymnt_inv                        10000 non-null float64\n",
      "total_rec_prncp                        10000 non-null float64\n",
      "total_rec_int                          10000 non-null float64\n",
      "last_pymnt_amnt                        10000 non-null float64\n",
      "mths_since_last_major_derog            9996 non-null float64\n",
      "policy_code                            10000 non-null float64\n",
      "tot_coll_amt                           9998 non-null float64\n",
      "tot_cur_bal                            10000 non-null float64\n",
      "total_rev_hi_lim                       10000 non-null float64\n",
      "credit_age                             10000 non-null float64\n",
      "credit_card_length                     10000 non-null float64\n",
      "pymnt_interval                         10000 non-null float64\n",
      "term_ 36 months                        10000 non-null uint8\n",
      "term_ 60 months                        10000 non-null uint8\n",
      "emp_length_1 year                      10000 non-null uint8\n",
      "emp_length_10+ years                   10000 non-null uint8\n",
      "emp_length_2 years                     10000 non-null uint8\n",
      "emp_length_3 years                     10000 non-null uint8\n",
      "emp_length_4 years                     10000 non-null uint8\n",
      "emp_length_5 years                     10000 non-null uint8\n",
      "emp_length_6 years                     10000 non-null uint8\n",
      "emp_length_7 years                     10000 non-null uint8\n",
      "emp_length_8 years                     10000 non-null uint8\n",
      "emp_length_9 years                     10000 non-null uint8\n",
      "emp_length_< 1 year                    10000 non-null uint8\n",
      "home_ownership_MORTGAGE                10000 non-null uint8\n",
      "home_ownership_OTHER                   10000 non-null uint8\n",
      "home_ownership_OWN                     10000 non-null uint8\n",
      "home_ownership_RENT                    10000 non-null uint8\n",
      "verification_status_Not Verified       10000 non-null uint8\n",
      "verification_status_Source Verified    10000 non-null uint8\n",
      "verification_status_Verified           10000 non-null uint8\n",
      "pymnt_plan_n                           10000 non-null uint8\n",
      "purpose_car                            10000 non-null uint8\n",
      "purpose_credit_card                    10000 non-null uint8\n",
      "purpose_debt_consolidation             10000 non-null uint8\n",
      "purpose_educational                    10000 non-null uint8\n",
      "purpose_home_improvement               10000 non-null uint8\n",
      "purpose_house                          10000 non-null uint8\n",
      "purpose_major_purchase                 10000 non-null uint8\n",
      "purpose_medical                        10000 non-null uint8\n",
      "purpose_moving                         10000 non-null uint8\n",
      "purpose_other                          10000 non-null uint8\n",
      "purpose_renewable_energy               10000 non-null uint8\n",
      "purpose_small_business                 10000 non-null uint8\n",
      "purpose_vacation                       10000 non-null uint8\n",
      "purpose_wedding                        10000 non-null uint8\n",
      "initial_list_status_f                  10000 non-null uint8\n",
      "initial_list_status_w                  10000 non-null uint8\n",
      "application_type_INDIVIDUAL            10000 non-null uint8\n",
      "application_type_JOINT                 10000 non-null uint8\n",
      "loan_status_ind_0                      10000 non-null uint8\n",
      "loan_status_ind_1                      10000 non-null uint8\n",
      "region_MidWest                         10000 non-null uint8\n",
      "region_NorthEast                       10000 non-null uint8\n",
      "region_SouthEast                       10000 non-null uint8\n",
      "region_SouthWest                       10000 non-null uint8\n",
      "region_West                            10000 non-null uint8\n",
      "dtypes: float64(31), uint8(46)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "random_sample2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438881    1\n",
       "465734    0\n",
       "595030    1\n",
       "282708    1\n",
       "347660    1\n",
       "437084    1\n",
       "656534    1\n",
       "468848    0\n",
       "234703    1\n",
       "704282    1\n",
       "742352    1\n",
       "480300    1\n",
       "765773    1\n",
       "856880    0\n",
       "544931    1\n",
       "52371     1\n",
       "71122     0\n",
       "670362    1\n",
       "76916     1\n",
       "444961    0\n",
       "407742    0\n",
       "549664    1\n",
       "665059    1\n",
       "493572    1\n",
       "280303    1\n",
       "742571    1\n",
       "111668    1\n",
       "771848    1\n",
       "154887    0\n",
       "825291    1\n",
       "         ..\n",
       "697892    0\n",
       "621236    1\n",
       "92882     0\n",
       "587740    1\n",
       "841445    1\n",
       "16083     0\n",
       "772691    1\n",
       "406718    1\n",
       "787041    1\n",
       "178883    0\n",
       "751742    1\n",
       "282376    1\n",
       "605833    1\n",
       "474305    1\n",
       "280005    0\n",
       "164916    0\n",
       "687663    1\n",
       "875354    0\n",
       "663153    1\n",
       "583662    1\n",
       "746751    1\n",
       "712812    1\n",
       "600224    1\n",
       "377006    1\n",
       "530892    1\n",
       "270317    1\n",
       "626555    1\n",
       "577265    1\n",
       "793296    1\n",
       "785743    1\n",
       "Name: loan_status_ind, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample['loan_status_ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loan_status_ind'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3062\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3063\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3064\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loan_status_ind'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-0171677ad26f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find correlations with the target and sort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcorrelations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loan_status_ind'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Display correlations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Most Positive Correlations:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2683\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2685\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2690\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2692\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3063\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3065\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loan_status_ind'"
     ]
    }
   ],
   "source": [
    " # Find correlations with the target and sort\n",
    "correlations = random_sample.corr()['loan_status_ind'].sort_values()\n",
    "\n",
    "# Display correlations\n",
    "print('Most Positive Correlations:\\n', correlations.tail(15))\n",
    "print('\\nMost Negative Correlations:\\n', correlations.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1:\n",
    "pca analysis and logistice regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "##PCA Analysis and logistic regression\n",
    "##import packages for PCA and logistic regression\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "##split the training data and the test data\n",
    "y=random_sample2[\"loan_status_ind\"]\n",
    "X=random_sample2.drop(\"loan_status_ind\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Standardize data\n",
    "# a.\n",
    "# b.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Make an instance of the model\n",
    "# pca = PCA(.95)\n",
    "# ##fit PCA to training data\n",
    "# pca.fit(X_train)\n",
    "\n",
    "# pca.n_components_\n",
    "# X_train = pca.transform(X_train)\n",
    "# X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "# all parameters not specified are set to their defaults\n",
    "# default solver is incredibly slow thats why we change it\n",
    "# solver = 'lbfgs'\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "# Returns a NumPy Array\n",
    "# Predict for One Observation (image)\n",
    "logisticRegr.predict(X_test[0].reshape(1,-1))\n",
    "# Predict for Multiple Observations (images) at Once\n",
    "logisticRegr.predict(X_test[0:10])\n",
    "# test the Model Performance\n",
    "score = logisticRegr.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature_importance_values\n",
    "features = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9856666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Make the random forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)\n",
    "\n",
    "# Train on the training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importance_values = random_forest.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': features, 'importance': feature_importance_values})\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = random_forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# test the model performance\n",
    "score = random_forest.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>out_prncp</td>\n",
       "      <td>0.181899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>out_prncp_inv</td>\n",
       "      <td>0.143897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>next_pymnt_d_Feb-2016</td>\n",
       "      <td>0.088182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>last_pymnt_d_Jan-2016</td>\n",
       "      <td>0.083275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>last_pymnt_amnt</td>\n",
       "      <td>0.082126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>last_credit_pull_d_Jan-2016</td>\n",
       "      <td>0.046305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>total_rec_prncp</td>\n",
       "      <td>0.033050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>total_rev_hi_lim</td>\n",
       "      <td>0.023679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>total_pymnt</td>\n",
       "      <td>0.022116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tot_cur_bal</td>\n",
       "      <td>0.021051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>last_pymnt_d_Dec-2015</td>\n",
       "      <td>0.017950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>total_pymnt_inv</td>\n",
       "      <td>0.014884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>next_pymnt_d_Jan-2016</td>\n",
       "      <td>0.010785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>collection_recovery_fee</td>\n",
       "      <td>0.008725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>last_pymnt_d_Oct-2015</td>\n",
       "      <td>0.008693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>recoveries</td>\n",
       "      <td>0.008253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>last_pymnt_d_Sep-2015</td>\n",
       "      <td>0.007738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>total_rec_int</td>\n",
       "      <td>0.006985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>last_credit_pull_d_Dec-2015</td>\n",
       "      <td>0.005976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>last_pymnt_d_Nov-2015</td>\n",
       "      <td>0.005917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>funded_amnt</td>\n",
       "      <td>0.005478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>installment</td>\n",
       "      <td>0.005476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>initial_list_status_w</td>\n",
       "      <td>0.005260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loan_amnt</td>\n",
       "      <td>0.005158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>funded_amnt_inv</td>\n",
       "      <td>0.004911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>initial_list_status_f</td>\n",
       "      <td>0.004814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>int_rate</td>\n",
       "      <td>0.004099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>last_pymnt_d_Aug-2015</td>\n",
       "      <td>0.003909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>0.003673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>revol_bal</td>\n",
       "      <td>0.003536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>earliest_cr_line_May-1980</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>earliest_cr_line_Aug-1967</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>earliest_cr_line_May-1978</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>earliest_cr_line_May-1977</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>earliest_cr_line_Aug-1981</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>earliest_cr_line_May-1975</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>earliest_cr_line_May-1974</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>earliest_cr_line_May-1973</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>earliest_cr_line_May-1971</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>earliest_cr_line_Aug-1969</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>earliest_cr_line_May-2009</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>earliest_cr_line_Oct-1977</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>earliest_cr_line_Nov-1979</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>earliest_cr_line_Oct-1967</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>earliest_cr_line_Oct-1966</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>earliest_cr_line_Oct-1964</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>earliest_cr_line_Nov-2009</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>earliest_cr_line_Nov-2008</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>earliest_cr_line_Feb-1981</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>earliest_cr_line_Nov-1984</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>earliest_cr_line_Nov-1977</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>earliest_cr_line_May-2010</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>earliest_cr_line_Nov-1976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>earliest_cr_line_Nov-1974</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>earliest_cr_line_Apr-2012</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>earliest_cr_line_Nov-1968</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>earliest_cr_line_Nov-1965</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>earliest_cr_line_Nov-1962</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>earliest_cr_line_May-2011</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>verification_status_joint_Verified</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>979 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                feature  importance\n",
       "16                            out_prncp    0.181899\n",
       "17                        out_prncp_inv    0.143897\n",
       "885               next_pymnt_d_Feb-2016    0.088182\n",
       "828               last_pymnt_d_Jan-2016    0.083275\n",
       "25                      last_pymnt_amnt    0.082126\n",
       "937         last_credit_pull_d_Jan-2016    0.046305\n",
       "20                      total_rec_prncp    0.033050\n",
       "45                     total_rev_hi_lim    0.023679\n",
       "18                          total_pymnt    0.022116\n",
       "33                          tot_cur_bal    0.021051\n",
       "814               last_pymnt_d_Dec-2015    0.017950\n",
       "19                      total_pymnt_inv    0.014884\n",
       "890               next_pymnt_d_Jan-2016    0.010785\n",
       "24              collection_recovery_fee    0.008725\n",
       "870               last_pymnt_d_Oct-2015    0.008693\n",
       "23                           recoveries    0.008253\n",
       "877               last_pymnt_d_Sep-2015    0.007738\n",
       "21                        total_rec_int    0.006985\n",
       "926         last_credit_pull_d_Dec-2015    0.005976\n",
       "863               last_pymnt_d_Nov-2015    0.005917\n",
       "1                           funded_amnt    0.005478\n",
       "4                           installment    0.005476\n",
       "794               initial_list_status_w    0.005260\n",
       "0                             loan_amnt    0.005158\n",
       "2                       funded_amnt_inv    0.004911\n",
       "793               initial_list_status_f    0.004814\n",
       "3                              int_rate    0.004099\n",
       "807               last_pymnt_d_Aug-2015    0.003909\n",
       "5                            annual_inc    0.003673\n",
       "13                            revol_bal    0.003536\n",
       "..                                  ...         ...\n",
       "635           earliest_cr_line_May-1980    0.000000\n",
       "319           earliest_cr_line_Aug-1967    0.000000\n",
       "633           earliest_cr_line_May-1978    0.000000\n",
       "632           earliest_cr_line_May-1977    0.000000\n",
       "331           earliest_cr_line_Aug-1981    0.000000\n",
       "630           earliest_cr_line_May-1975    0.000000\n",
       "629           earliest_cr_line_May-1974    0.000000\n",
       "628           earliest_cr_line_May-1973    0.000000\n",
       "627           earliest_cr_line_May-1971    0.000000\n",
       "320           earliest_cr_line_Aug-1969    0.000000\n",
       "664           earliest_cr_line_May-2009    0.000000\n",
       "716           earliest_cr_line_Oct-1977    0.000000\n",
       "677           earliest_cr_line_Nov-1979    0.000000\n",
       "711           earliest_cr_line_Oct-1967    0.000000\n",
       "710           earliest_cr_line_Oct-1966    0.000000\n",
       "709           earliest_cr_line_Oct-1964    0.000000\n",
       "706           earliest_cr_line_Nov-2009    0.000000\n",
       "705           earliest_cr_line_Nov-2008    0.000000\n",
       "417           earliest_cr_line_Feb-1981    0.000000\n",
       "681           earliest_cr_line_Nov-1984    0.000000\n",
       "675           earliest_cr_line_Nov-1977    0.000000\n",
       "665           earliest_cr_line_May-2010    0.000000\n",
       "674           earliest_cr_line_Nov-1976    0.000000\n",
       "673           earliest_cr_line_Nov-1974    0.000000\n",
       "318           earliest_cr_line_Apr-2012    0.000000\n",
       "669           earliest_cr_line_Nov-1968    0.000000\n",
       "668           earliest_cr_line_Nov-1965    0.000000\n",
       "667           earliest_cr_line_Nov-1962    0.000000\n",
       "666           earliest_cr_line_May-2011    0.000000\n",
       "978  verification_status_joint_Verified    0.000000\n",
       "\n",
       "[979 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.sort_values(by = ['importance'],ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model3: Decisiontree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9763333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf1 = tree.DecisionTreeClassifier()\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "\n",
    "# test model performance\n",
    "score = clf1.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model4: NeroNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf2 = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "clf2.fit(X_train, y_train)                         \n",
    "\n",
    "# test model performance\n",
    "score = clf2.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 979 and input n_features is 2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-c68a178364d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                      np.arange(y_min, y_max, plot_step))\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontourf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPaired\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \"\"\"\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    672\u001b[0m             pred = sum((estimator.predict(X) == classes).T * w\n\u001b[1;32m    673\u001b[0m                        for estimator, w in zip(self.estimators_,\n\u001b[0;32m--> 674\u001b[0;31m                                                self.estimator_weights_))\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_weights_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# self.algorithm == \"SAMME\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             pred = sum((estimator.predict(X) == classes).T * w\n\u001b[0;32m--> 673\u001b[0;31m                        for estimator, w in zip(self.estimators_,\n\u001b[0m\u001b[1;32m    674\u001b[0m                                                self.estimator_weights_))\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \"\"\"\n\u001b[1;32m    411\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tree_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    382\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 979 and input n_features is 2 "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "\n",
    "\n",
    "# Construct dataset\n",
    "X1, y1 = make_gaussian_quantiles(cov=2.,\n",
    "                                 n_samples=200, n_features=2,\n",
    "                                 n_classes=2, random_state=1)\n",
    "X2, y2 = make_gaussian_quantiles(mean=(3, 3), cov=1.5,\n",
    "                                 n_samples=300, n_features=2,\n",
    "                                 n_classes=2, random_state=1)\n",
    "X = np.concatenate((X1, X2))\n",
    "y = np.concatenate((y1, - y2 + 1))\n",
    "\n",
    "# Create and fit an AdaBoosted decision tree\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)\n",
    "\n",
    "bdt.fit(X_train, y_train)\n",
    "\n",
    "plot_colors = \"br\"\n",
    "plot_step = 0.02\n",
    "class_names = \"AB\"\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the decision boundaries\n",
    "plt.subplot(121)\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                     np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "Z = bdt.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "# Plot the training points\n",
    "for i, n, c in zip(range(2), class_names, plot_colors):\n",
    "    idx = np.where(y == i)\n",
    "    plt.scatter(X[idx, 0], X[idx, 1],\n",
    "                c=c, cmap=plt.cm.Paired,\n",
    "                s=20, edgecolor='k',\n",
    "                label=\"Class %s\" % n)\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Decision Boundary')\n",
    "\n",
    "# Plot the two-class decision scores\n",
    "twoclass_output = bdt.decision_function(X)\n",
    "plot_range = (twoclass_output.min(), twoclass_output.max())\n",
    "plt.subplot(122)\n",
    "for i, n, c in zip(range(2), class_names, plot_colors):\n",
    "    plt.hist(twoclass_output[y == i],\n",
    "             bins=10,\n",
    "             range=plot_range,\n",
    "             facecolor=c,\n",
    "             label='Class %s' % n,\n",
    "             alpha=.5,\n",
    "             edgecolor='k')\n",
    "x1, x2, y1, y2 = plt.axis()\n",
    "plt.axis((x1, x2, y1, y2 * 1.2))\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Samples')\n",
    "plt.xlabel('Score')\n",
    "plt.title('Decision Scores')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.35)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crossvalidation\n",
    "# sklearn cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Grid Search for 2-3 hypaprameter in each model\n",
    "#  sklearn grid search\n",
    "# tuning your model to find the optimal hype"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Project-lending club.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
